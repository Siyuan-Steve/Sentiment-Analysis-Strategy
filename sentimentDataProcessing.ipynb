{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from dateutil import tz\n",
    "import sys,time\n",
    "import numpy as np\n",
    "from_zone = tz.gettz('UTC')\n",
    "to_zone = tz.gettz('America/New_York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ticker.csv') as file:\n",
    "    tickers=file.read().split(',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sp1500ticker.csv') as file:\n",
    "    sp1500tickers=file.read().split('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is used to select Dow Jones stocks' news. DON'T run it in IPYTHON NOTEBOOK, run it in CMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#Consider only relevance==1\n",
    "###\n",
    "# with open('USARelevance1Only.csv') as infile:\n",
    "#     with open('DJRelevance1Only.csv','w')as outfile:\n",
    "#         for line in infile:\n",
    "#             curLine=line.split(',')\n",
    "#             if curLine[1] in tickers:\n",
    "#                 outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "#Consider only relevance==1 SP1500\n",
    "###\n",
    "# with open('USARelevance1Only.csv') as infile:\n",
    "#     with open('SP1500Relevance1Only.csv','w')as outfile:\n",
    "#         for line in infile:\n",
    "#             curLine=line.split(',')\n",
    "#             if curLine[1] in sp1500tickers:\n",
    "#                 outfile.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##Consider all relevance\n",
    "# with open('USSentimentReleAll.csv') as infile:\n",
    "#     with open('DJRelevanceAll.csv','w')as outfile:\n",
    "#         for line in infile:\n",
    "#             curLine=line.split(',')\n",
    "#             if curLine[1] in tickers:\n",
    "#                 outfile.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we get the financial news sentiment of Dow Jones from 2000.1.1-2017.9.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.999%"
     ]
    }
   ],
   "source": [
    "##relavance==1 condition\n",
    "i=0\n",
    "marketDateRel1=[]\n",
    "with open('DJRelevance1Only.csv') as infile:\n",
    "        for line in infile:\n",
    "            curLine=line.split(',')\n",
    "            if curLine[0]!=\"Time\":\n",
    "                utc=curLine[0]\n",
    "                utc=datetime.datetime.strptime(utc, '%Y-%m-%d %H:%M:%S')\n",
    "                utc = utc.replace(tzinfo=from_zone)\n",
    "                est = utc.astimezone(to_zone)\n",
    "                #print(est)\n",
    "                date=est.date()\n",
    "                dayStart=datetime.datetime.combine(est.date()-datetime.timedelta(days=1),datetime.time(16,00)).astimezone(tz.gettz('America/New_York'))\n",
    "                dayEnd=datetime.datetime.combine(est.date(),datetime.time(16,00)).astimezone(tz.gettz('America/New_York'))\n",
    "                if est>dayStart and est<=dayEnd:\n",
    "                    if est>datetime.datetime.combine(est.date(),datetime.time(00,00)).astimezone(tz.gettz('America/New_York')):\n",
    "                                                     curDate=est.date()\n",
    "                    else:\n",
    "                                                     curDate=est.date()+datetime.timedelta(days=1)\n",
    "                else:\n",
    "                    curDate=est.date()+datetime.timedelta(days=1)\n",
    "                curDateString=str(curDate)\n",
    "                marketDateRel1.append(curDateString)\n",
    "                # track progress    \n",
    "                i+=1\n",
    "                if i%100==0: # See the process of the whole program\n",
    "                    sys.stdout.write('\\r%.3f%%'%((i+1)*100/533307))\n",
    "                    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.999%"
     ]
    }
   ],
   "source": [
    "##relavance==1 condition SP1500\n",
    "i=0\n",
    "marketDateSP1500Rel1=[]\n",
    "with open('SP1500Relevance1Only.csv') as infile:\n",
    "        for line in infile:\n",
    "            curLine=line.split(',')\n",
    "            if curLine[0]!=\"UTCtime\":\n",
    "                utc=curLine[0]\n",
    "                utc=datetime.datetime.strptime(utc, '%Y-%m-%d %H:%M:%S')\n",
    "                utc = utc.replace(tzinfo=from_zone)\n",
    "                est = utc.astimezone(to_zone)\n",
    "                #print(est)\n",
    "                date=est.date()\n",
    "                dayStart=datetime.datetime.combine(est.date()-datetime.timedelta(days=1),datetime.time(16,00)).astimezone(tz.gettz('America/New_York'))\n",
    "                dayEnd=datetime.datetime.combine(est.date(),datetime.time(16,00)).astimezone(tz.gettz('America/New_York'))\n",
    "                if est>dayStart and est<=dayEnd:\n",
    "                    if est>datetime.datetime.combine(est.date(),datetime.time(00,00)).astimezone(tz.gettz('America/New_York')):\n",
    "                                                     curDate=est.date()\n",
    "                    else:\n",
    "                                                     curDate=est.date()+datetime.timedelta(days=1)\n",
    "                else:\n",
    "                    curDate=est.date()+datetime.timedelta(days=1)\n",
    "                curDateString=str(curDate)\n",
    "                marketDateSP1500Rel1.append(curDateString)\n",
    "                # track progress    \n",
    "                i+=1\n",
    "                if i%100==0: # See the process of the whole program\n",
    "                    sys.stdout.write('\\r%.3f%%'%((i+1)*100/4938329))\n",
    "                    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Market Date SP1500 rel==1 to csv\n",
    "marketDateSP1500Rel1df = pd.DataFrame(data={\"MarketDate\": marketDateSP1500Rel1})\n",
    "marketDateSP1500Rel1df.to_csv(\"marketDateSP1500Rel1\", sep='\\n',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-09-30',\n",
       " '2017-10-01']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marketDateSP1500Rel1[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## any relavance condition\n",
    "i=0\n",
    "marketDateRelAll=[]\n",
    "with open('DJRelevanceAll.csv') as infile:\n",
    "        for line in infile:\n",
    "            curLine=line.split(',')\n",
    "            if curLine[0]!=\"UTCtime\":\n",
    "                utc=curLine[0]\n",
    "                utc=datetime.datetime.strptime(utc, '%Y-%m-%d %H:%M:%S')\n",
    "                utc = utc.replace(tzinfo=from_zone)\n",
    "                est = utc.astimezone(to_zone)\n",
    "                #print(est)\n",
    "                date=est.date()\n",
    "                dayStart=datetime.datetime.combine(est.date()-datetime.timedelta(days=1),datetime.time(16,00)).astimezone(tz.gettz('America/New_York'))\n",
    "                dayEnd=datetime.datetime.combine(est.date(),datetime.time(16,00)).astimezone(tz.gettz('America/New_York'))\n",
    "                if est>dayStart and est<=dayEnd:\n",
    "                    if est>datetime.datetime.combine(est.date(),datetime.time(00,00)).astimezone(tz.gettz('America/New_York')):\n",
    "                                                     curDate=est.date()\n",
    "                    else:\n",
    "                                                     curDate=est.date()+datetime.timedelta(days=1)\n",
    "                else:\n",
    "                    curDate=est.date()+datetime.timedelta(days=1)\n",
    "                curDateString=str(curDate)\n",
    "                marketDateRelAll.append(curDateString)\n",
    "                # track progress    \n",
    "                i+=1\n",
    "                if i%100==0: # See the process of the whole program\n",
    "                    sys.stdout.write('\\r%.3f%%'%((i+1)*100/1342878))\n",
    "                    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relecance==1\n",
    "djSentiment=pd.read_csv('DJRelevance1Only.csv')\n",
    "djSentiment['MarketDate']  = np.array(marketDateRel1)\n",
    "#Export to csv to use mysql to filter\n",
    "djSentiment.to_csv('djSentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relecance==1 SP1500\n",
    "sp1500Sentiment=pd.read_csv('SP1500Relevance1Only.csv')\n",
    "sp1500Sentiment['MarketDate']  = np.array(marketDateSP1500Rel1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export to csv\n",
    "sp1500Sentiment.to_csv('sp1500Sentiment.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2000-01-01 17:36:00</th>\n",
       "      <th>F</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4938308</th>\n",
       "      <td>2017-09-29 23:33:34</td>\n",
       "      <td>KALU</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938309</th>\n",
       "      <td>2017-09-29 23:39:03</td>\n",
       "      <td>KNX</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938310</th>\n",
       "      <td>2017-09-29 23:48:41</td>\n",
       "      <td>CRVL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938311</th>\n",
       "      <td>2017-09-29 23:56:54</td>\n",
       "      <td>ACM</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938312</th>\n",
       "      <td>2017-09-30 00:32:04</td>\n",
       "      <td>MOH</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938313</th>\n",
       "      <td>2017-09-30 00:33:27</td>\n",
       "      <td>PATK</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938314</th>\n",
       "      <td>2017-09-30 01:15:34</td>\n",
       "      <td>MCK</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938315</th>\n",
       "      <td>2017-09-30 01:34:17</td>\n",
       "      <td>PATK</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938316</th>\n",
       "      <td>2017-09-30 01:36:15</td>\n",
       "      <td>PATK</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938317</th>\n",
       "      <td>2017-09-30 03:15:24</td>\n",
       "      <td>FTI</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938318</th>\n",
       "      <td>2017-09-30 03:25:22</td>\n",
       "      <td>TECD</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938319</th>\n",
       "      <td>2017-09-30 06:32:09</td>\n",
       "      <td>HOG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938320</th>\n",
       "      <td>2017-09-30 06:32:23</td>\n",
       "      <td>NYT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938321</th>\n",
       "      <td>2017-09-30 06:32:42</td>\n",
       "      <td>LLY</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938322</th>\n",
       "      <td>2017-09-30 06:32:47</td>\n",
       "      <td>CME</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938323</th>\n",
       "      <td>2017-09-30 06:32:50</td>\n",
       "      <td>FB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938324</th>\n",
       "      <td>2017-09-30 06:32:50</td>\n",
       "      <td>FB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938325</th>\n",
       "      <td>2017-09-30 06:47:42</td>\n",
       "      <td>LLY</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938326</th>\n",
       "      <td>2017-09-30 15:02:39</td>\n",
       "      <td>SCG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4938327</th>\n",
       "      <td>2017-09-30 23:57:00</td>\n",
       "      <td>DISH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         2000-01-01 17:36:00     F  0\n",
       "4938308  2017-09-29 23:33:34  KALU -1\n",
       "4938309  2017-09-29 23:39:03   KNX -1\n",
       "4938310  2017-09-29 23:48:41  CRVL  0\n",
       "4938311  2017-09-29 23:56:54   ACM -1\n",
       "4938312  2017-09-30 00:32:04   MOH -1\n",
       "4938313  2017-09-30 00:33:27  PATK -1\n",
       "4938314  2017-09-30 01:15:34   MCK -1\n",
       "4938315  2017-09-30 01:34:17  PATK -1\n",
       "4938316  2017-09-30 01:36:15  PATK -1\n",
       "4938317  2017-09-30 03:15:24   FTI -1\n",
       "4938318  2017-09-30 03:25:22  TECD  1\n",
       "4938319  2017-09-30 06:32:09   HOG  0\n",
       "4938320  2017-09-30 06:32:23   NYT  0\n",
       "4938321  2017-09-30 06:32:42   LLY -1\n",
       "4938322  2017-09-30 06:32:47   CME  0\n",
       "4938323  2017-09-30 06:32:50    FB  0\n",
       "4938324  2017-09-30 06:32:50    FB  0\n",
       "4938325  2017-09-30 06:47:42   LLY -1\n",
       "4938326  2017-09-30 15:02:39   SCG  0\n",
       "4938327  2017-09-30 23:57:00  DISH  0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp1500Sentiment[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relecance = ANY\n",
    "djSentimentRelAll=pd.read_csv('DJRelevanceAll.csv')\n",
    "djSentimentRelAll['MarketDate']  = np.array(marketDateRelAll)\n",
    "#Export to csv to use mysql to filter\n",
    "djSentimentRelAll.to_csv('djSentimentRelAll.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "senti = defaultdict(str)\n",
    "for ticker in tickers:\n",
    "    filename=ticker+\"SentimentRelAll.csv\"\n",
    "    senti['%s'%ticker]=pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "price = defaultdict(str)\n",
    "for ticker in tickers:\n",
    "    filename=ticker+\"price.csv\"\n",
    "    price['%s'%ticker]=pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ticker</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/3/2000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/4/2000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/5/2000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/6/2000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/7/2000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Date ticker  price\n",
       "0  1/3/2000   AAPL   4.00\n",
       "1  1/4/2000   AAPL   3.66\n",
       "2  1/5/2000   AAPL   3.71\n",
       "3  1/6/2000   AAPL   3.39\n",
       "4  1/7/2000   AAPL   3.55"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price['AAPL'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#select DJstock price\n",
    "#     with open('sp1500price.csv') as infile:\n",
    "#         with open('DJprice.csv','w')as outfile:\n",
    "#             for line in infile:\n",
    "#                 curLine=line.split('\\t')\n",
    "#                 if curLine[1] in tickers:\n",
    "#                     outfile.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
