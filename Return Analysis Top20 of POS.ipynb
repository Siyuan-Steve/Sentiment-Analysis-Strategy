{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import os\n",
    "from scipy import stats\n",
    "import sys\n",
    "#import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing Data: 100.00%-SAIC"
     ]
    }
   ],
   "source": [
    "result = {}\n",
    "tickerFile = \"./sp1500data/sp1500tickerWoSlash.csv\"\n",
    "with open(tickerFile) as csvfile:\n",
    "    tickers = csvfile.read().split(\"\\n\")\n",
    "i = 0\n",
    "for ticker in tickers:\n",
    "    pricepFile = \"./sp1500data/sp1500data/sp1500adjustedPrice/daily_adjusted_\"+ticker+\".csv\"\n",
    "    sentimentFile = \"./sp1500data/sp1500data/sp1500sentiment/\"+ticker+\"Sentiment.csv\"\n",
    "    priceData = pd.read_csv(pricepFile, sep=\",\",low_memory=False)\n",
    "    sentimentData = pd.read_csv(sentimentFile, sep=\",\", skiprows=1,\n",
    "                         names = [\"UTCTime\",\"Ticker\",\"Sentiment\",\"Date\"], low_memory=False)\n",
    "    if not priceData.empty:\n",
    "        priceData.timestamp = priceData.timestamp.apply(lambda x: pd.to_datetime(x,format='%Y-%m-%d').date())\n",
    "        priceData = priceData.set_index(\"timestamp\").sort_index()\n",
    "        priceData[\"Return\"] = priceData.adjusted_close/priceData.adjusted_close.shift(1) - 1\n",
    "        sentimentData = sentimentData.drop(\"UTCTime\", axis=1)\n",
    "        sentimentData.Date = sentimentData.Date.apply(lambda x: pd.to_datetime(x,format='%Y-%m-%d').date())\n",
    "        sentimentData = sentimentData.set_index(\"Date\")\n",
    "        Score = sentimentData.groupby(\"Date\")[\"Sentiment\"].apply(lambda x: np.log((list(x).count(1)+1)/(list(x).count(-1)+1)))\n",
    "        result[ticker] = pd.merge(priceData, Score.to_frame(), how = \"left\", left_index = True, right_index = True)\n",
    "    i += 1\n",
    "    sys.stdout.write( '\\r Processing Data: %.2f%%-%s' % (((i * 100 / (len(tickers)))), ticker))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, n): # data is a one-dimensional list, n is days of moving-average\n",
    "    if n<len(data):\n",
    "        data = np.array(data)\n",
    "        residual = (data[n:]-data[:-n])/n\n",
    "        reslist=np.append(np.mean(data[:n]),residual)\n",
    "        firstndaysMA = [np.mean(data[:i+1]) for i in range(n-1)]\n",
    "        return np.append(firstndaysMA,np.cumsum(reslist))\n",
    "    else:\n",
    "        return [np.mean(data[:i+1]) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing Data: 100.00%-SAIC"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "nshort=5\n",
    "nlong=26\n",
    "for ticker in tickers:\n",
    "    result[ticker][\"shortMA\"]=moving_average(result[ticker][\"adjusted_close\"],nshort)\n",
    "    result[ticker][\"longMA\"]=moving_average(result[ticker][\"adjusted_close\"],nlong)\n",
    "    result[ticker][\"shortMA/longMA\"]=result[ticker][\"shortMA\"]/result[ticker][\"longMA\"]\n",
    "    i+=1\n",
    "    sys.stdout.write( '\\r Processing Data: %.2f%%-%s' % (((i * 100 / (len(tickers)))), ticker))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing Data: 99.96%-2017-11-20"
     ]
    }
   ],
   "source": [
    "####initial code to trade top 20% of POS sentiment score the stocks\n",
    "tickersUse = [k for k in result.keys()]\n",
    "nclass = 5\n",
    "quantileReturn = {i:[] for i in range(nclass)}\n",
    "Dates = result[\"AAPL\"].index\n",
    "dailyTotalTicker=[]\n",
    "returnEachDay={}\n",
    "for i in range(len(Dates)-1):\n",
    "    Date = Dates[i]\n",
    "    scoreList = []\n",
    "    nextdayReturnList = []\n",
    "    dailyTotalTicker=[]\n",
    "    maRatio=[]\n",
    "    fileName=\"./sp1500data/combinedMAData/combined_\"+str(Date)+\".csv\"\n",
    "    for ticker in tickersUse:\n",
    "        if Date in result[ticker].index and Dates[i+1] in result[ticker].index:\n",
    "            if not np.isnan(result[ticker].loc[Date][\"Sentiment\"]) and not np.isnan(result[ticker].loc[Dates[i+1]][\"Return\"]):\n",
    "                scoreList.append(result[ticker].loc[Date][\"Sentiment\"])\n",
    "                nextdayReturnList.append(result[ticker].loc[Dates[i+1]][\"Return\"]) \n",
    "                dailyTotalTicker.append(ticker)\n",
    "                maRatio.append(result[ticker].loc[Date][\"shortMA/longMA\"])\n",
    "    returnEachDay[Date]=pd.DataFrame()\n",
    "    returnEachDay[Date][\"ticker\"]=np.array(dailyTotalTicker)\n",
    "    returnEachDay[Date][\"SentimentScore\"]=np.array(scoreList)\n",
    "    returnEachDay[Date][\"nextDayReturn\"]=np.array(nextdayReturnList)\n",
    "    returnEachDay[Date][\"maRatio\"]=np.array(np.array(maRatio))\n",
    "    returnEachDay[Date].to_csv(fileName,sep=\",\")\n",
    "    sys.stdout.write( '\\r Processing Data: %.2f%%-%s' % (((i * 100 / (len(Dates)))), str(Date)))\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Dates)-1):\n",
    "    Date = Dates[i]\n",
    "    returnEachDay[Date][\"price/high\"]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TrendStratV3 import TrendStrat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=TrendStrat(tickerList=\"sp1500ticker.csv\",stratPeriod=\"12d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricedata=TrendStrat.readData(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating Data: 7.69%-BRKX"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lisiy\\Quant Method in Investment\\TrendStratV3.py:144: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  dailyReturn.append(rawData[\"adjusted_close\"][i]/rawData[\"adjusted_close\"][i-1]-1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generating Data: 100.00%-SPYK"
     ]
    }
   ],
   "source": [
    "finalData=TrendStrat.generateAllTickers(a,pricedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing Data: 0.00%-2000-01-03"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lisiy\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processing Data: 99.16%-2017-09-29"
     ]
    }
   ],
   "source": [
    "for i in range(len(Dates)-1):\n",
    "    Date = Dates[i]\n",
    "    fileName=\"./sp1500data/combinedData/combined_\"+str(Date)+\".csv\"\n",
    "    for ticker in returnEachDay[Date][\"ticker\"]:\n",
    "        sys.stdout.write( '\\r Processing Data: %.2f%%-%s' % (((i * 100 / (len(Dates)))), str(Date)))\n",
    "        sys.stdout.flush()\n",
    "        if finalData[ticker]['price/high'][str(Date)] and isinstance(finalData[ticker]['price/high'][str(Date)], (int, float, complex)):\n",
    "            returnEachDay[Date][\"price/high\"][returnEachDay[Date][\"ticker\"]==ticker]=finalData[ticker]['price/high'][str(Date)]\n",
    "        else:\n",
    "            returnEachDay[Date][\"price/high\"][returnEachDay[Date][\"ticker\"]==ticker]=0\n",
    "    returnEachDay[Date].to_csv(fileName,sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "2400\n",
      "2800\n",
      "3200\n",
      "3600\n",
      "4000\n",
      "4400\n"
     ]
    }
   ],
   "source": [
    "sum1=1\n",
    "for i in range(len(Dates)-1):\n",
    "    if i%400 ==0: print(i)\n",
    "    Date = Dates[i]\n",
    "    if (topSentimentList[Date]['nextDayReturn'].sum()/(len(topSentimentList[Date])+1))!=float('Inf'):\n",
    "        sum1*=(1+topSentimentList[Date]['nextDayReturn'].sum()/(len(topSentimentList[Date])+1))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "400\n",
      "800\n",
      "1200\n",
      "1600\n",
      "2000\n",
      "2400\n",
      "2800\n",
      "3200\n",
      "3600\n",
      "4000\n",
      "4400\n"
     ]
    }
   ],
   "source": [
    "topSentimentList={}\n",
    "posSentimentList={}\n",
    "for i in range(len(Dates)-1):\n",
    "    if i%400 ==0: print(i)\n",
    "    Date = Dates[i]\n",
    "    posSentimentList[Date]=returnEachDay[Date][returnEachDay[Date][\"SentimentScore\"]>0]\n",
    "    n = len(posSentimentList)//5\n",
    "    topSentimentList[Date]= posSentimentList[Date].nlargest(n,'SentimentScore')\n",
    "    sys.stdout.write( '\\r Processing Data: %.2f%%-%s' % (((i * 100 / (len(Dates)))), str(Date)))\n",
    "    sys.stdout.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
